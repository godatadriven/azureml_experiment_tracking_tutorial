{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will leverage mlflow to keep track of our experiments and models. MLflow Tracking is organized around the concept of runs, which are executions of some piece of data science code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Run, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the file\n",
    "DATA_DIR = Path(\"data/\")\n",
    "df_train = pd.read_csv(DATA_DIR/'train.csv')\n",
    "df_test = pd.read_csv(DATA_DIR/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameters:\n",
      "gridsearch-n_estimators [10, 25, 100]\n",
      "gridsearch-criterion ['gini', 'entropy']\n",
      "gridsearch-max_depth [2, 5, 10, None]\n"
     ]
    }
   ],
   "source": [
    "# We define the hyperparameters we want to tune\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 25, 100],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [2, 5, 10, None],\n",
    "}\n",
    "n_cross_vals = 5\n",
    "print(\"Hyper-parameters:\")\n",
    "for param, value in param_grid.items():\n",
    "    print(f\"gridsearch-{param}\", str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MLflow</b> stores the details of a run like logs, code versions, data, and model artifacts. The first thing we need to do is tell MLFlow where to store the logs.\n",
    "\n",
    "We can do this using a MLFlow tracking URI ([docs](https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_tracking_uri)). An MLflow tracking uri can be a local directory, database, or mlflow server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the currect tracking uri.\n",
    "mlflow.is_tracking_uri_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training will be done in this notebook, but the logs will be collected in the clouds.\n",
    "\n",
    "In AzureML, you can get and set the tracking URI by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the AzureML workspace.\n",
    "workspace = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureML workspace mlflow uri: azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourceGroups/prashant-srivastava-sandbox/providers/Microsoft.MachineLearningServices/workspaces/azureml-mlflow?\n"
     ]
    }
   ],
   "source": [
    "azure_ws_mlflow_tracking_uri = workspace.get_mlflow_tracking_uri()\n",
    "print(f\"AzureML workspace mlflow uri: {azure_ws_mlflow_tracking_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourceGroups/prashant-srivastava-sandbox/providers/Microsoft.MachineLearningServices/workspaces/azureml-mlflow?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(azure_ws_mlflow_tracking_uri)\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create mlflow runs to record our training experiments.\n",
    "AzureML allows to create mlflow runs as Jobs. These jobs are create under an Experiment namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1678278807682, experiment_id='61468a99-3ed0-4291-89c7-3227fca073ac', last_update_time=None, lifecycle_stage='active', name='DevExp', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create AzureML Experiment and use it for this run.\n",
    "# If you do not create an Experiment, AzureML will create a Default experiment for runs.\n",
    "experiment = Experiment(workspace, 'DevExp')\n",
    "mlflow.set_experiment('DevExp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting mlflow run with id d66d0956-e52e-4e58-9c5c-1318db9a0c0d\n",
      "Fitting the model...\n",
      "Done! Test accuracy: 0.975\n",
      "Logging to mlflow.\n"
     ]
    }
   ],
   "source": [
    "# Start mlflow run\n",
    "with mlflow.start_run(\n",
    "    run_name=f\"MyTraining\"\n",
    ") as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Starting mlflow run with id {run_id}\")\n",
    "    for param, value in param_grid.items():\n",
    "        mlflow.log_param(f\"gridsearch/{param}\", str(value))\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=n_cross_vals, n_jobs=-1)\n",
    "\n",
    "    # We train the model\n",
    "    print(f\"Fitting the model...\")\n",
    "    grid_search.fit(df_train[[\"x1\", \"x2\"]], df_train[\"y\"])\n",
    "    model = grid_search.best_estimator_\n",
    "    \n",
    "    # Here we evaluate the model\n",
    "    predictions = model.predict(df_test[[\"x1\", \"x2\"]])\n",
    "    test_accuracy = accuracy_score(df_test[\"y\"], predictions)\n",
    "    print(f\"Done! Test accuracy: {test_accuracy}\")\n",
    "\n",
    "    # We log the accuracy to azureml using mlflow\n",
    "    # You can see the logged metrics in the azureml UI under the \"Metrics\" tab\n",
    "    print(\"Logging to mlflow.\")\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    # We log the selected hyper-parameters to azureml using mlflow\n",
    "    # You can find the best hyper-parameters in the azureml UI under parameters.\n",
    "    for k, v in grid_search.best_params_.items():\n",
    "        mlflow.log_param(f\"selected-{k}\", v)\n",
    "\n",
    "    # Export the model and log it to azureml using mlflow\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        dump(model, f\"{tmp_dir}/model.joblib\")\n",
    "        mlflow.log_artifact(f\"{tmp_dir}/model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>DevExp</td><td>d66d0956-e52e-4e58-9c5c-1318db9a0c0d</td><td></td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/d66d0956-e52e-4e58-9c5c-1318db9a0c0d?wsid=/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourcegroups/prashant-srivastava-sandbox/workspaces/azureml-mlflow&amp;tid=3d4d17ea-1ae4-4705-947e-51369c5a5f79\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: DevExp,\n",
       "Id: d66d0956-e52e-4e58-9c5c-1318db9a0c0d,\n",
       "Type: None,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = Run.get(workspace=workspace, run_id=run_id)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'DevModel'.\n",
      "2023/03/08 12:34:23 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: DevModel, version 1\n",
      "Created version '1' of model 'DevModel'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1678278863844, current_stage='None', description='', last_updated_timestamp=1678278863844, name='DevModel', run_id='d66d0956-e52e-4e58-9c5c-1318db9a0c0d', run_link='', source='azureml://experiments/DevExp/runs/d66d0956-e52e-4e58-9c5c-1318db9a0c0d/artifacts/model.joblib', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_path = \"model.joblib\"\n",
    "model_uri = f\"runs:/{run.id}/{artifact_path}\"\n",
    "\n",
    "mlflow.register_model(model_uri=model_uri, name='DevModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(workspace=Workspace.create(name='azureml-mlflow', subscription_id='8e155238-93f7-4377-9b62-6a2f4e51052e', resource_group='prashant-srivastava-sandbox'), name=DevModel, id=DevModel:1, version=1, tags={}, properties={'azureml.artifactPrefix': 'ExperimentRun/dcid.d66d0956-e52e-4e58-9c5c-1318db9a0c0d/model.joblib', 'mlflow.modelSourceUri': 'azureml://experiments/DevExp/runs/d66d0956-e52e-4e58-9c5c-1318db9a0c0d/artifacts/model.joblib'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.list(workspace=workspace, name='DevModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c54ad65707ef7d43a84ed93777f96f49399a61e6aa29f567d32d6a9c442faf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
