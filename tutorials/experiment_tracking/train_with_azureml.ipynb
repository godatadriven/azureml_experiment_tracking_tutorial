{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will make use of AzureML storage and compute resources for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import mlflow\n",
    "from azureml.core import Dataset, Workspace, Experiment, Environment, ScriptRunConfig\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir):\n",
    "    \"\"\"Generate data from make_moons and save it to a folder.\n",
    "    \"\"\"\n",
    "    X, y = make_moons(n_samples=1000, shuffle=True, noise=0.2, random_state=42)\n",
    "    df = pd.DataFrame({\"x1\": X[:, 0], \"x2\": X[:, 1], \"y\": y})\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = create_dataset(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace from config.\n",
    "workspace = Workspace.from_config()\n",
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DevDataset': DatasetRegistration(id='2d328165-e7d4-42a1-9f8d-43ce19d39d4c', name='DevDataset', version=1, description='', tags={}), 'moon_dataset': DatasetRegistration(id='72340cf3-b97f-479f-9822-9c3045247aa1', name='moon_dataset', version=1, description='', tags={})}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to datasets/Dev/\n",
      "Uploading an estimated of 2 files\n",
      "Target already exists. Skipping upload for datasets/Dev/test.csv\n",
      "Target already exists. Skipping upload for datasets/Dev/train.csv\n",
      "Uploaded 0 files\n",
      "Creating new dataset\n"
     ]
    }
   ],
   "source": [
    "# Register the dataset to AzureML workspace\n",
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    # We can only upload from disk, so we save it to a temporary directory.\n",
    "    df_train.to_csv(f\"{tmp_dir}/train.csv\", index=False)\n",
    "    df_test.to_csv(f\"{tmp_dir}/test.csv\", index=False)\n",
    "\n",
    "    # Upload the datasets to the default datastore (blobstore container)\n",
    "    # In this container it puts it inside the \"datasets/moons\" folder\n",
    "    blob_store_path = \"datasets/Dev/\"\n",
    "    Dataset.File.upload_directory(tmp_dir, (datastore, blob_store_path))\n",
    "    \n",
    "    # Create a dataset from the uploaded files and register it.\n",
    "    dataset = Dataset.File.from_files(path=[(datastore, blob_store_path)])\n",
    "    dataset.register(workspace, \"DevDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"DevDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-1-training/code/Users/Prashant.Srivastava/azureml_experiment_tracking_tutorial/tutorials/experiment_tracking/data/test.csv',\n",
       " '/mnt/batch/tasks/shared/LS_root/mounts/clusters/vm-1-training/code/Users/Prashant.Srivastava/azureml_experiment_tracking_tutorial/tutorials/experiment_tracking/data/train.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(workspace=workspace, name=dataset_name)\n",
    "\n",
    "# We can also download the data from AzureML\n",
    "dataset.download(str(DATA_DIR), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset in AzureML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml://westeurope.api.azureml.ms/mlflow/v1.0/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourceGroups/prashant-srivastava-sandbox/providers/Microsoft.MachineLearningServices/workspaces/azureml-mlflow?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_ws_mlflow_tracking_uri = workspace.get_mlflow_tracking_uri()\n",
    "mlflow.set_tracking_uri(azure_ws_mlflow_tracking_uri)\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will the job under an experiemnt alias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"dev-train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1677848179318, experiment_id='60e8daa9-a127-4d3e-b658-66af46706393', last_update_time=None, lifecycle_stage='active', name='dev-train', tags={}>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the same Experiment space that we used earlier.\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using compute engine for training the model. \n",
    "\n",
    "For this, we need:\n",
    "- An AzureML compute intance (has already been created for you).\n",
    "- A custom python environment for your compute instance.\n",
    "- Scripts containing the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_name = \"vm-1-Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>State</th><th>Location</th><th>VmSize</th><th>Application URI</th><th>Docs</th></tr><tr><td><a href=\"https://ml.azure.com/compute/vm-1-Training/details?wsid=/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourcegroups/prashant-srivastava-sandbox/workspaces/azureml-mlflow\" target=\"_blank\" rel=\"noopener\">vm-1-Training</a></td><td><a href=\"https://ml.azure.com?wsid=/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourcegroups/prashant-srivastava-sandbox/workspaces/azureml-mlflow&amp;tid=3d4d17ea-1ae4-4705-947e-51369c5a5f79\" target=\"_blank\" rel=\"noopener\">azureml-mlflow</a></td><td>Running</td><td>westeurope</td><td>STANDARD_DS1_V2</td><td><a href=\"https://vm-1-training.westeurope.instances.azureml.ms/tree/\" target=\"_blank\" rel=\"noopener\">Jupyter</a>  <a href=\"https://vm-1-training.westeurope.instances.azureml.ms/lab\" target=\"_blank\" rel=\"noopener\">JupyterLab</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computeinstance.ComputeInstance?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Doc</a></td></tr></table>"
      ],
      "text/plain": [
       "{\n",
       "  \"id\": \"/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourceGroups/prashant-srivastava-sandbox/providers/Microsoft.MachineLearningServices/workspaces/azureml-mlflow/computes/vm-1-Training\",\n",
       "  \"name\": \"vm-1-Training\",\n",
       "  \"location\": \"westeurope\",\n",
       "  \"tags\": {},\n",
       "  \"properties\": {\n",
       "    \"description\": \"Compute VM for Srivastava.prashant898@gmail.com\",\n",
       "    \"computeType\": \"ComputeInstance\",\n",
       "    \"computeLocation\": \"westeurope\",\n",
       "    \"resourceId\": null,\n",
       "    \"provisioningErrors\": null,\n",
       "    \"provisioningState\": \"Succeeded\",\n",
       "    \"properties\": {\n",
       "      \"vmSize\": \"STANDARD_DS1_V2\",\n",
       "      \"applications\": [\n",
       "        {\n",
       "          \"displayName\": \"Jupyter\",\n",
       "          \"endpointUri\": \"https://vm-1-training.westeurope.instances.azureml.ms/tree/\"\n",
       "        },\n",
       "        {\n",
       "          \"displayName\": \"Jupyter Lab\",\n",
       "          \"endpointUri\": \"https://vm-1-training.westeurope.instances.azureml.ms/lab\"\n",
       "        }\n",
       "      ],\n",
       "      \"connectivityEndpoints\": {\n",
       "        \"publicIpAddress\": \"20.23.163.205\",\n",
       "        \"privateIpAddress\": \"10.0.0.5\"\n",
       "      },\n",
       "      \"sshSettings\": {\n",
       "        \"sshPublicAccess\": \"Disabled\",\n",
       "        \"adminUserName\": \"azureuser\",\n",
       "        \"adminPublicKey\": null,\n",
       "        \"sshPort\": 4001\n",
       "      },\n",
       "      \"personalComputeInstanceSettings\": {\n",
       "        \"assignedUser\": {\n",
       "          \"objectId\": \"4f96a420-68e6-4900-97af-c2cc3532935a\",\n",
       "          \"tenantId\": \"3d4d17ea-1ae4-4705-947e-51369c5a5f79\"\n",
       "        }\n",
       "      },\n",
       "      \"subnet\": {\n",
       "        \"id\": null\n",
       "      },\n",
       "      \"errors\": []\n",
       "    },\n",
       "    \"status\": {\n",
       "      \"errors\": [],\n",
       "      \"creationTime\": \"2023-02-28T09:34:14.500850+00:00\",\n",
       "      \"createdBy\": {\n",
       "        \"userObjectId\": \"7d35a0ff-b53c-4dd9-b41a-afe0553eb7b6\",\n",
       "        \"userTenantId\": \"3d4d17ea-1ae4-4705-947e-51369c5a5f79\",\n",
       "        \"userName\": null\n",
       "      },\n",
       "      \"modifiedTime\": \"2023-03-08T09:54:01.493019+00:00\",\n",
       "      \"state\": \"Running\",\n",
       "      \"vmSize\": \"STANDARD_DS1_V2\"\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get your compute machine\n",
    "ComputeTarget(workspace=workspace, name=compute_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_path = \"../../requirements.txt\"\n",
    "environment_name = \"dev-environment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new custom environment\n",
    "env = Environment.from_pip_requirements(\n",
    "        name=environment_name,\n",
    "        file_path=str(requirements_path),\n",
    ")\n",
    "# Python version must be added in this unclear way\n",
    "env.python.conda_dependencies.set_python_version(\"3.8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to run three scripts:\n",
    "1. Download the dataset to our compute instace.\n",
    "2. Run the training with MLflow.\n",
    "3. Register the model to AzureML models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a script to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing download_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile download_dataset.py\n",
    "from argparse import ArgumentParser\n",
    "from azureml.core import Workspace, Dataset\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--dataset_name', \n",
    "    type=str, \n",
    "    default='moon_dataset', \n",
    "    help='The name of the dataset to download. The dataset must be registered in AzureML.')\n",
    "parser.add_argument(\n",
    "    '--output_folder', \n",
    "    type=str, \n",
    "    default='data', \n",
    "    help='The folder to save the dataset to.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "workspace = Workspace.from_config()\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, args.dataset_name)\n",
    "dataset.download(args.output_folder, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a script for training the model with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_with_mlflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_with_mlflow.py\n",
    "import tempfile\n",
    "from argparse import ArgumentParser\n",
    "from typing import Any\n",
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from azureml.core import Workspace\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--train_dataset\", type=str, default=\"data/train.csv\")\n",
    "parser.add_argument(\"--test_dataset\", type=str, default=\"data/test.csv\")\n",
    "parser.add_argument(\"--n_cross_vals\", type=int, default=5)\n",
    "parser.add_argument(\"--max_depth\", default=[2, 5, 10, None])\n",
    "parser.add_argument(\"--n_estimators\", default=[10, 25, 100])\n",
    "parser.add_argument(\"--criterion\", default=[\"gini\", \"entropy\"])\n",
    "\n",
    "args = parser.parse_args()\n",
    "# This can be used to log all metrics and artifacts that are generated by the model.\n",
    "# mlflow.autolog(log_models=True)\n",
    "workspace = Workspace.from_config()\n",
    "\n",
    "df_train = pd.read_csv(args.train_dataset)\n",
    "df_test = pd.read_csv(args.test_dataset)\n",
    "\n",
    "# We define the hyperparameters we want to tune\n",
    "param_grid = {\n",
    "    \"n_estimators\": args.n_estimators,\n",
    "    \"criterion\": args.criterion,\n",
    "    \"max_depth\": args.max_depth,\n",
    "}\n",
    "# We log the selected hyper-parameters to azureml using mlflow\n",
    "# You can find the best hyper-parameters in the azureml UI under parameters.\n",
    "\n",
    "mlflow.set_tracking_uri(workspace.get_mlflow_tracking_uri())\n",
    "\n",
    "with mlflow.start_run(\n",
    "    run_name=f\"Moon_training-{datetime.now().strftime('%m/%d/%Y,%H:%M:%S')}\"\n",
    ") as run:\n",
    "    run_id = run.info.run_id\n",
    "    for param, value in param_grid.items():\n",
    "        mlflow.log_param(f\"gridsearch/{param}\", str(value))\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=args.n_cross_vals, n_jobs=-1)\n",
    "\n",
    "    # We train the model\n",
    "    grid_search.fit(df_train[[\"x1\", \"x2\"]], df_train[\"y\"])\n",
    "    model = grid_search.best_estimator_\n",
    "\n",
    "    # Here we evaluate the model\n",
    "    predictions = model.predict(df_test[[\"x1\", \"x2\"]])\n",
    "    test_accuracy = accuracy_score(df_test[\"y\"], predictions)\n",
    "\n",
    "    # We log the accuracy to azureml using mlflow\n",
    "    # You can see the logged metrics in the azureml UI under the \"Metrics\" tab\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "    # We log the selected hyper-parameters to azureml using mlflow\n",
    "    # You can find the best hyper-parameters in the azureml UI under parameters.\n",
    "    for k, v in grid_search.best_params_.items():\n",
    "        mlflow.log_param(f\"selected/{k}\", v)\n",
    "    \n",
    "    # Export the model and log it to azureml using mlflow\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        dump(model, f\"{tmp_dir}/model.joblib\")\n",
    "        mlflow.log_artifact(f\"{tmp_dir}/model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a script to register the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model.py\n",
    "from argparse import ArgumentParser\n",
    "import mlflow\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--model_name\", \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help=\"Name of the model to register.\")\n",
    "parser.add_argument(\n",
    "    \"--run_id\",\n",
    "    type=str,\n",
    "    default=None,\n",
    "    required=False,\n",
    "    help=(\n",
    "        \"ID AzureML has given the run.\"\n",
    "        \"You can find in the UI under raw json properties. \"\n",
    "        \"If not provided, it will try to get it from the mlflow context.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "model_name = args.model_name\n",
    "if args.run_id is not None:\n",
    "    run_id =  args.run_id\n",
    "run_id = Run.get_context(allow_offline=False)\n",
    "run_id = run_id.id\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "# Set the tracking URI to the AzureML workspace\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "\n",
    "# the artifact path is the path where the model artifact is stored within the run.\n",
    "artifact_path = \"model.joblib\"\n",
    "model_uri = f\"runs:/{run_id}/{artifact_path}\"\n",
    "mlflow.register_model(model_uri=model_uri, name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in all the three scripts, we are creating Workspace object from config. We need to keep the config file along the scripts, so that the scripts can use it for authenticating the Workspace. We can do this by: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.write_config(file_name='./config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the scripts, we can start running the script on out compute instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\n",
    "    \"python download_dataset.py --dataset_name moon_dataset --output_folder data\",\n",
    "    \"python train_with_mlflow.py --train_dataset data/train.csv --test_dataset data/test.csv\",\n",
    "    \"python register_model.py --model_name moon_model\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we combine all the configuration\n",
    "script_run_config = ScriptRunConfig(\n",
    "    source_directory=str(source_directory),\n",
    "    command=\" && \".join(commands),\n",
    "    compute_target=compute_name,\n",
    "    environment=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You follow the experiment here:\n",
      "https://ml.azure.com/experiments/id/60e8daa9-a127-4d3e-b658-66af46706393?wsid=/subscriptions/8e155238-93f7-4377-9b62-6a2f4e51052e/resourcegroups/prashant-srivastava-sandbox/workspaces/azureml-mlflow&tid=3d4d17ea-1ae4-4705-947e-51369c5a5f79\n"
     ]
    }
   ],
   "source": [
    "# Here we submit the configuration as an experiment job to AzureML.\n",
    "experiment.submit(script_run_config)\n",
    "print(\"You follow the experiment here:\")\n",
    "print(experiment.get_portal_url())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c54ad65707ef7d43a84ed93777f96f49399a61e6aa29f567d32d6a9c442faf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
